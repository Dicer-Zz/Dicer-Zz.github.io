<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>基于word2vec的红楼梦人物关系分析 - Dicer&#039;s blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Dicer&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Dicer&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="word2vec是Google公司在2013年提出的一种词嵌入算法。使用word2vec算法对词汇进行向量化后，原来的近义词在向量空间中是邻近的，因此word2vec可以很好的保留原来词汇之间的相似性。"><meta property="og:type" content="blog"><meta property="og:title" content="Dicer&#039;s Blog"><meta property="og:url" content="https://blog.dicer.fun/2021/05/18/%E5%9F%BA%E4%BA%8Eword2vec%E7%9A%84%E7%BA%A2%E6%A5%BC%E6%A2%A6%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90/"><meta property="og:site_name" content="Dicer&#039;s blog"><meta property="og:description" content="word2vec是Google公司在2013年提出的一种词嵌入算法。使用word2vec算法对词汇进行向量化后，原来的近义词在向量空间中是邻近的，因此word2vec可以很好的保留原来词汇之间的相似性。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.dicer.fun/gallery/cover/hlm.png"><meta property="article:published_time" content="2021-05-18T09:02:44.000Z"><meta property="article:modified_time" content="2021-05-18T14:21:16.851Z"><meta property="article:author" content="Dicer"><meta property="article:tag" content="红楼梦"><meta property="article:tag" content="word2vec"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/gallery/cover/hlm.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.dicer.fun/2021/05/18/%E5%9F%BA%E4%BA%8Eword2vec%E7%9A%84%E7%BA%A2%E6%A5%BC%E6%A2%A6%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90/"},"headline":"基于word2vec的红楼梦人物关系分析","image":["https://blog.dicer.fun/gallery/cover/hlm.png"],"datePublished":"2021-05-18T09:02:44.000Z","dateModified":"2021-05-18T14:21:16.851Z","author":{"@type":"Person","name":"Dicer"},"description":"word2vec是Google公司在2013年提出的一种词嵌入算法。使用word2vec算法对词汇进行向量化后，原来的近义词在向量空间中是邻近的，因此word2vec可以很好的保留原来词汇之间的相似性。"}</script><link rel="canonical" href="https://blog.dicer.fun/2021/05/18/%E5%9F%BA%E4%BA%8Eword2vec%E7%9A%84%E7%BA%A2%E6%A5%BC%E6%A2%A6%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90/"><link rel="icon" href="/img/favicon.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.png" alt="Dicer&#039;s blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Dicer-Zz"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Home Page" href="https://dicer.fun"><i class="fas fa-dice"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/gallery/cover/hlm.png" alt="基于word2vec的红楼梦人物关系分析"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-05-18T09:02:44.000Z" title="2021/5/18 下午5:02:44">2021-05-18</time>发表</span><span class="level-item"><time dateTime="2021-05-18T14:21:16.851Z" title="2021/5/18 下午10:21:16">2021-05-18</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">10 分钟读完 (大约1538个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">基于word2vec的红楼梦人物关系分析</h1><div class="content"><p>word2vec是Google公司在2013年提出的一种词嵌入算法。使用word2vec算法对词汇进行向量化后，原来的近义词在向量空间中是邻近的，因此word2vec可以很好的保留原来词汇之间的相似性。</p>
<span id="more"></span>

<p>本文使用gensim库实现的word2vec算法，对红楼梦中的人物关系进行分析，得到了许多有趣的结论。</p>
<h1 id="获取文本"><a href="#获取文本" class="headerlink" title="获取文本"></a>获取文本</h1><p>首先我们需要获取原著的本文文件，并且需要保证文本文件足够「纯净」，可以减少文本处理的工作量。</p>
<p>可以通过爬虫，从<a target="_blank" rel="noopener" href="http://www.purepen.com获取原始文本。">http://www.purepen.com获取原始文本。</a></p>
<p>爬虫代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crawler</span>():</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    爬取红楼梦</span></span><br><span class="line"><span class="string">    :url</span></span><br><span class="line"><span class="string">    :return</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    path = <span class="string">&#x27;http://www.purepen.com/hlm/&#x27;</span></span><br><span class="line">    file = <span class="built_in">open</span>(<span class="string">&#x27;./data/红楼梦.txt&#x27;</span>, <span class="string">&#x27;w+&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">121</span>):</span><br><span class="line">        url = path + (<span class="string">&#x27;000&#x27;</span>+<span class="built_in">str</span>(page))[-<span class="number">3</span>:] + <span class="string">&#x27;.htm&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(url)</span><br><span class="line">        html = requests.get(url)</span><br><span class="line">        html.encoding = html.apparent_encoding</span><br><span class="line">        soup = BeautifulSoup(html.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line">        title = soup.find(align = <span class="string">&#x27;center&#x27;</span>).text</span><br><span class="line">        <span class="built_in">print</span>(title)</span><br><span class="line">        content = soup.find(face = <span class="string">&#x27;宋体&#x27;</span>).text</span><br><span class="line">        file.write(title   + <span class="string">&#x27;\t\n&#x27;</span>)</span><br><span class="line">        file.write(content + <span class="string">&#x27;\t\n&#x27;</span>)</span><br><span class="line">        sec = random.randint(<span class="number">0</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Sleep %d sconds.&quot;</span> % sec)</span><br><span class="line">        time.sleep(sec)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    crawler()</span><br></pre></td></tr></table></figure>

<p>代码中通过sleep机制简单的避免了被反爬。</p>
<h1 id="文本处理"><a href="#文本处理" class="headerlink" title="文本处理"></a>文本处理</h1><p>首先需要使用正则表达式将所有的标点符号去掉。红楼梦属于半白话文半文言文的问题，因此其中许多词语分词系统是不能识别的，但是因为我们这次做的只是人物关系，所以只需要把所有的人名写入用户字典就可以保证所有的人名都能被准确地识别出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">segment</span>():</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    content = <span class="built_in">open</span>(<span class="string">&#x27;./data/红楼梦.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).read()</span><br><span class="line">    trimed = re.sub(<span class="string">r&#x27;[^\u4e00-\u9fa5]&#x27;</span>, <span class="string">&#x27; &#x27;</span>, content)</span><br><span class="line">    jieba.load_userdict(<span class="string">&#x27;./data/dict.txt&#x27;</span>)</span><br><span class="line">    result = <span class="string">&#x27; &#x27;</span>.join(jieba.cut(trimed))</span><br><span class="line">    file = <span class="built_in">open</span>(<span class="string">&#x27;./data/cut_result.txt&#x27;</span>, <span class="string">&#x27;w+&#x27;</span>)</span><br><span class="line">    file.write(<span class="string">&#x27; &#x27;</span>.join(result.split()))</span><br><span class="line">    cost = time.time() - start</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Segment cost: <span class="subst">&#123;cost:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>按道理应该是要去掉停用词的，不过我不想做，偷个懒。😛</p>
<h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><p>使用gensim实现的word2vec算法进行向量化，因为文本不是很大，所以向量长度我选择的200，window大小选择的3。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_model</span>():</span></span><br><span class="line">    start = time.time()</span><br><span class="line">    sentencePath = <span class="string">&#x27;./data/cut_result.txt&#x27;</span></span><br><span class="line">    modelPath = <span class="string">&#x27;./data/hlm_model&#x27;</span></span><br><span class="line">    sentence = word2vec.LineSentence(sentencePath)</span><br><span class="line">    model = word2vec.Word2Vec(sentence, vector_size=<span class="number">200</span>, window=<span class="number">3</span>)</span><br><span class="line">    model.save(modelPath)</span><br><span class="line">    cost = time.time() - start</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Word2Vec model training cost: <span class="subst">&#123;cost:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>训练起来还是很快的，大概一秒钟就好了。</p>
<h1 id="PCA降维"><a href="#PCA降维" class="headerlink" title="PCA降维"></a>PCA降维</h1><p>因为原始的向量长度太大，所以我们可以先用PCA（主成分分析）将向量降到二维，然后在坐标系中画出来。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot</span><br><span class="line"></span><br><span class="line">pyplot.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;Arial Unicode MS&#x27;</span>]</span><br><span class="line"></span><br><span class="line">model = word2vec.Word2Vec.load(<span class="string">&#x27;./data/hlm_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line">allNames = [x.strip(<span class="string">&#x27;\n&#x27;</span>) <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;./data/name.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>).readlines()]</span><br><span class="line">X, names = [], []</span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> allNames:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        X.append(model.wv[name])</span><br><span class="line">        names.append(name)</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;missed name: &quot;</span>, name)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">result = pca.fit_transform(X)</span><br><span class="line"></span><br><span class="line">pyplot.scatter(result[:, <span class="number">0</span>], result[:, <span class="number">1</span>])</span><br><span class="line"><span class="keyword">for</span> i, name <span class="keyword">in</span> <span class="built_in">enumerate</span>(names):</span><br><span class="line">	pyplot.annotate(name, xy=(result[i, <span class="number">0</span>], result[i, <span class="number">1</span>]))</span><br><span class="line"><span class="comment"># pyplot.show()</span></span><br><span class="line">pyplot.savefig(<span class="string">&#x27;./data/relation.png&#x27;</span>, transparent=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>因为word2vec会忽略掉频次比较小的词语，所以我们在获取词向量时需要进行异常捕捉。</p>
<p>让我们看一下效果吧！</p>
<p><img src="/gallery/others/hlm-all.png" alt="整体图片"></p>
<p>因为名字有点多，整体看起来有点拥挤。我们把焦点放在又下角，可以看到宝黛钗三个人都在，我们放大一下。</p>
<p><img src="/gallery/others/hlm-part.png" alt="右下角局部"></p>
<p>我们可以看到宝玉和黛玉紧紧挨着一起，宝黛一生吹好吧！</p>
<h1 id="最相似分析"><a href="#最相似分析" class="headerlink" title="最相似分析"></a>最相似分析</h1><p>word2vec中提供了几个有趣的方法，我们可以用这些方法进一步分析一下人物关系。</p>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> word2vec</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">analyse</span>():</span></span><br><span class="line">    model = word2vec.Word2Vec.load(<span class="string">&#x27;./data/hlm_model&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 宝玉:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;宝玉&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 黛玉:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;黛玉&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 宝钗:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;宝钗&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 晴雯:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;晴雯&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 袭人:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;袭人&#x27;</span>]))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Nearest 贾母:&#x27;</span>,model.wv.most_similar([<span class="string">&#x27;贾母&#x27;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(model.wv.doesnt_match(<span class="string">u&quot;贾宝玉 薛宝钗 林黛玉 史湘云&quot;</span>.split()))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.doesnt_match(<span class="string">u&quot;黛玉 元春 探春 迎春 惜春&quot;</span>.split()))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.doesnt_match(<span class="string">u&quot;贾琏 贾政 贾赦 贾敬&quot;</span>.split()))</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;贾宝玉&#x27;</span>,<span class="string">&#x27;林黛玉&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;林黛玉&#x27;</span>,<span class="string">&#x27;薛宝钗&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;晴雯&#x27;</span>, <span class="string">&#x27;袭人&#x27;</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;林黛玉&#x27;</span>,<span class="string">&#x27;薛宝钗&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;林黛玉&#x27;</span>,<span class="string">&#x27;宝钗&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;黛玉&#x27;</span>,<span class="string">&#x27;薛宝钗&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(model.wv.similarity(<span class="string">&#x27;黛玉&#x27;</span>,<span class="string">&#x27;宝钗&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    who = model.wv[<span class="string">&#x27;宝玉&#x27;</span>] - model.wv[<span class="string">&#x27;宝钗&#x27;</span>] + model.wv[<span class="string">&#x27;黛玉&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(model.wv.most_similar(positive=[who]))</span><br><span class="line">    who = model.wv[<span class="string">&#x27;宝玉&#x27;</span>] - model.wv[<span class="string">&#x27;黛玉&#x27;</span>] + model.wv[<span class="string">&#x27;宝钗&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(model.wv.most_similar(positive=[who]))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    analyse()</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Nearest 宝玉: [(&#x27;黛玉&#x27;, 0.9654377102851868), (&#x27;袭人&#x27;, 0.9432756304740906), (&#x27;贾琏&#x27;, 0.9404013156890869), (&#x27;紫鹃&#x27;, 0.9312815070152283), (&#x27;晴雯&#x27;, 0.9278832674026489), (&#x27;鸳鸯&#x27;, 0.9248123168945312), (&#x27;湘云&#x27;, 0.9108842015266418), (&#x27;凤姐&#x27;, 0.9095652103424072), (&#x27;宝钗&#x27;, 0.9087227582931519), (&#x27;薛姨妈&#x27;, 0.9083631634712219)]</span><br><span class="line">Nearest 黛玉: [(&#x27;宝玉&#x27;, 0.9654375910758972), (&#x27;宝钗&#x27;, 0.9516232013702393), (&#x27;湘云&#x27;, 0.9490573406219482), (&#x27;贾琏&#x27;, 0.9195422530174255), (&#x27;喜不自胜&#x27;, 0.9156811237335205), (&#x27;晴雯&#x27;, 0.9114517569541931), (&#x27;雨村&#x27;, 0.9069087505340576), (&#x27;鸳鸯&#x27;, 0.9047612547874451), (&#x27;紫鹃&#x27;, 0.9041048884391785), (&#x27;杜撰&#x27;, 0.9008530974388123)]</span><br><span class="line">Nearest 宝钗: [(&#x27;探春&#x27;, 0.958204448223114), (&#x27;湘云&#x27;, 0.9580698609352112), (&#x27;黛玉&#x27;, 0.9516231417655945), (&#x27;贾琏&#x27;, 0.9483581185340881), (&#x27;惜春&#x27;, 0.9394745826721191), (&#x27;薛姨妈&#x27;, 0.9329902529716492), (&#x27;雨村&#x27;, 0.9322482943534851), (&#x27;杜撰&#x27;, 0.9264885783195496), (&#x27;紫鹃&#x27;, 0.9231323003768921), (&#x27;喜不自胜&#x27;, 0.9216738939285278)]</span><br><span class="line">Nearest 晴雯: [(&#x27;紫鹃&#x27;, 0.9769253730773926), (&#x27;袭人&#x27;, 0.9697536826133728), (&#x27;凤姐儿&#x27;, 0.9683317542076111), (&#x27;香菱&#x27;, 0.9670401215553284), (&#x27;鸳鸯&#x27;, 0.9620832800865173), (&#x27;拍手&#x27;, 0.9574575424194336), (&#x27;薛姨妈&#x27;, 0.956330418586731), (&#x27;贾琏&#x27;, 0.9559655785560608), (&#x27;陪笑&#x27;, 0.9534842371940613), (&#x27;湘云&#x27;, 0.9519651532173157)]</span><br><span class="line">Nearest 袭人: [(&#x27;紫鹃&#x27;, 0.9749440550804138), (&#x27;晴雯&#x27;, 0.9697537422180176), (&#x27;凤姐儿&#x27;, 0.9651725888252258), (&#x27;鸳鸯&#x27;, 0.9604008793830872), (&#x27;平儿&#x27;, 0.9592967629432678), (&#x27;凤姐&#x27;, 0.9534151554107666), (&#x27;贾琏&#x27;, 0.9518244862556458), (&#x27;薛姨妈&#x27;, 0.9457788467407227), (&#x27;宝玉&#x27;, 0.9432753920555115), (&#x27;香菱&#x27;, 0.9285346269607544)]</span><br><span class="line">Nearest 贾母: [(&#x27;王夫人&#x27;, 0.9712321162223816), (&#x27;尤氏&#x27;, 0.9515039324760437), (&#x27;贾珍&#x27;, 0.9488133192062378), (&#x27;贾琏&#x27;, 0.9456284046173096), (&#x27;薛姨妈&#x27;, 0.937038779258728), (&#x27;凤姐&#x27;, 0.9299778938293457), (&#x27;鸳鸯&#x27;, 0.9244546890258789), (&#x27;邢夫人&#x27;, 0.9219790101051331), (&#x27;贾蓉&#x27;, 0.9125443696975708), (&#x27;雪雁&#x27;, 0.9032955765724182)]</span><br><span class="line">史湘云</span><br><span class="line">元春</span><br><span class="line">贾敬</span><br><span class="line">0.9830096</span><br><span class="line">0.9892198</span><br><span class="line">0.96975374</span><br><span class="line">0.9892198</span><br><span class="line">0.6931182</span><br><span class="line">0.64615595</span><br><span class="line">0.95162314</span><br><span class="line">[(&#x27;宝玉&#x27;, 0.9627019166946411), (&#x27;黛玉&#x27;, 0.9240608215332031), (&#x27;袭人&#x27;, 0.8599908351898193), (&#x27;晴雯&#x27;, 0.8383870720863342), (&#x27;紫鹃&#x27;, 0.8329888582229614), (&#x27;贾琏&#x27;, 0.8326756954193115), (&#x27;鸳鸯&#x27;, 0.829352080821991), (&#x27;湘云&#x27;, 0.8235012292861938), (&#x27;一想&#x27;, 0.8234348297119141), (&#x27;香菱&#x27;, 0.8150357007980347)]</span><br><span class="line">[(&#x27;贾琏&#x27;, 0.9775873422622681), (&#x27;宝钗&#x27;, 0.964641809463501), (&#x27;紫鹃&#x27;, 0.958747923374176), (&#x27;薛姨妈&#x27;, 0.9540018439292908), (&#x27;宝玉&#x27;, 0.9533487558364868), (&#x27;袭人&#x27;, 0.9529389142990112), (&#x27;鸳鸯&#x27;, 0.9496896266937256), (&#x27;凤姐&#x27;, 0.9492440223693848), (&#x27;晴雯&#x27;, 0.9458354115486145), (&#x27;凤姐儿&#x27;, 0.9457259178161621)]</span><br></pre></td></tr></table></figure>

<p>从上面的结果可以看到，宝玉最相似的是黛玉，黛玉最相似的是宝玉，而宝钗最相似的是探春。</p>
<p>并且可以看到「宝玉」和「黛玉」的相似度比「贾宝玉」和「黛玉」的相似度更高，说明在文中前者往往是成对出现的。</p>
<p>另外，我们还得到了两个有趣的式子：<br>$$<br>宝玉 - 宝钗 + 黛玉 \approx 宝玉<br>$$</p>
<p>$$<br>宝玉 - 黛玉 + 宝钗 \approx 贾琏<br>$$</p>
<p>很有意思😂</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>基于word2vec的红楼梦人物关系分析</p><p><a href="https://blog.dicer.fun/2021/05/18/基于word2vec的红楼梦人物关系分析/">https://blog.dicer.fun/2021/05/18/基于word2vec的红楼梦人物关系分析/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Dicer</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-05-18</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2021-05-18</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E7%BA%A2%E6%A5%BC%E6%A2%A6/">红楼梦</a><a class="link-muted mr-2" rel="tag" href="/tags/word2vec/">word2vec</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipayQR.JPG" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechatQR.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/05/22/%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">基本操作</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/05/05/sklearn%E8%B8%A9%E5%9D%91/"><span class="level-item">sklearn踩坑</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Dicer"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Dicer</p><p class="is-size-6 is-block">Trying to reach the star.</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">43</p></a></div></div></nav></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><figure class="media-left"><a class="image" href="/2021/11/27/Primailty-Test-A-survey/"><img src="/gallery/cover/Prime.png" alt="素性测试：A Survey"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-11-27T14:08:39.000Z">2021-11-27</time></p><p class="title"><a href="/2021/11/27/Primailty-Test-A-survey/">素性测试：A Survey</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/11/25/LeetCode-2081-Sum-of-k-Mirror-Numbers/"><img src="/gallery/thumbnails/dicer.png" alt="LeetCode 2081. Sum of k-Mirror Numbers"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-11-25T02:25:11.000Z">2021-11-25</time></p><p class="title"><a href="/2021/11/25/LeetCode-2081-Sum-of-k-Mirror-Numbers/">LeetCode 2081. Sum of k-Mirror Numbers</a></p><p class="categories"><a href="/categories/LeetCode/">LeetCode</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/09/30/The-image-spider-of-Zhihu/"><img src="/gallery/others/zhihu.png" alt="知乎回答图片爬虫"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-09-30T05:57:50.000Z">2021-09-30</time></p><p class="title"><a href="/2021/09/30/The-image-spider-of-Zhihu/">知乎回答图片爬虫</a></p><p class="categories"><a href="/categories/%E7%BD%91%E7%BB%9C/">网络</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/06/28/The-deviation-of-cross-entropy-with-softmax/"><img src="/gallery/cover/softmax.png" alt="The deviation of cross entropy with softmax"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-06-28T14:53:07.000Z">2021-06-28</time></p><p class="title"><a href="/2021/06/28/The-deviation-of-cross-entropy-with-softmax/">The deviation of cross entropy with softmax</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article><article class="media"><figure class="media-left"><a class="image" href="/2021/05/22/%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"><img src="/gallery/cover/JBCZ.png" alt="基本操作"></a></figure><div class="media-content"><p class="date"><time dateTime="2021-05-22T14:22:25.000Z">2021-05-22</time></p><p class="title"><a href="/2021/05/22/%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/">基本操作</a></p><p class="categories"><a href="/categories/NLP/">NLP</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.png" alt="Dicer&#039;s blog" height="28"></a><p class="is-size-7"><span>&copy; 2021 Dicer</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Dicer-Zz"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: false,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>